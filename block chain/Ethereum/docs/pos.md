### 什么是Proof of Stake（权益证明机制）

权益证明机制是公有链共识演算法的一类，乙太坊接下来的Casper 演算法是其中之一。它和比特币、目前的以太坊及许多其他区块链背后的Proof of Work有着相似的作用，但在安全性及能源使用效率上有着显著的优点。

总的来说，权益证明机制演算法大致如下。区块链记录着一组**validator**（验证者），所有持有该区块链数位货币的使用者（即以太坊的以太币）都可藉由一个特殊交易将他们的数位货币锁进一个存库来成为验证者。创造一个新的区块的过程则藉由一个验证者参与的共识演算法来进行。

目前有许多种的共识演算法及许多种奖赏验证者的方式，因此有许多不同种类的权益证明机制。从一个演算法的角度，主要分为两种： 链型态的权益证明机制及Byzantine Fault Tolerance（ BFT，拜占庭容错）相似的权益证明机制。

在链型态的权益证明机制中，演算法在每个时间区间（例如每十秒为一区间）里以伪随机的方式选择验证者，并赋予其创造一个区块的权利。而这个区块如同区块链，必须指向之前的区块（通常是指向最长链的最新区块），并随时间拉长，成为单一条持续增长的链。

在拜占庭容错相似的权益证明机制中，某个验证者被随机指派来_提议_（propose）新的区块，每一轮每个验证者将票（vote）投给特定的区块，经过多轮投票来决定区块是否有效。在过程结束之后，该区块是否合法会达成永久的共识，即不会再改变。

### 权益证明机制在和工作量证明机制相比下有哪些优点？

详细说明可见：[ A Proof of Stake Design Philosophy ](https://medium.com/@VitalikButerin/a-proof-of-stake-design-philosophy-506585978d51)里有更完整的论述。

简短来说：
*不需要为了达成链的安全而**消耗大量电力**，（估计以太坊和比特币每天都会各消耗一百万美元在电力及硬体成本上）。
*因为不需要消耗大量电力，所以**没有发行等量的货币的需要**来提供加入网路的动机。理论上什至可以有净量为负值的发行量--透过销毁一部分的交易手续费的方式来达成。
*权益证明机制提供了更多赛局理论的发挥空间，来**降低中心化组织的形成**，以及在组织已形成的情况下，可能的方法来防止他们进一步伤害网路（例如工作量证明机制中的[ selfish mining ](https://www.cs.cornell.edu/~ie53/publications/btcProcFC.pdf)）。
*  **减少中心化造成的风险**。因为采用权益证明机制后，矿工（验证者）要扩展规模将不会是个问题。在工作量证明机制中，当你资本多到一定程度，你可以负担更好的规模生产设备，拉大和其他人的差距（投入一千万的成本所获得的收益不只是投入一百万的十倍）。而在权益证明机制中，相比于一百万货币，持有一千万的货币会保证让你获得十倍的报酬，而且是以公平的方式。
*可以利用经济上的惩罚来**大大地提高不同51%攻击方式在权益证明机制中所需要的成本**，引用Vlad Zamfir所述--"想像一参与51%攻击你的ASIC工厂就会被烧毁"。

### 权益证明机制和传统的拜占庭容错研究怎么结合？

拜占庭容错研究中有一些重要的结论是适用到各种共识演算法中的，包含传统的演算法如PBFT，同时也可用在任何权益证明机制中。如果搭配恰当的数学模型，甚至可以用在工作量证明机制中。

这些重要的结论包含：

* [ **CAP理论** ](https://en.wikipedia.org/wiki/CAP_theorem) - "如果网路发生阻断（partition）时，你只能选择资料的一致性（consistency）或可用性（availability），无法两者兼得"。论点很直觉：如果网路因阻断而分隔为二，在其中一边我送出一笔交易："将我的十元给A"；在另一半我送出另一笔交易："将我的十元给B "。则此时系统要不是(1）无可用性，即这两笔交易至少会有一笔交易不会被接受；要不就是(2）无一致性，一半看到的是A多了十元而另一半则看到B多了十元。要注意的是，CAP理论和扩展性（scalability）是无关的，他在分片（sharded）或非分片的系统皆适用。

* [ **FLP impossibility** ](http://the-paper-trail.org/blog/a-brief-tour-of-flp-impossibility/) -在非同步（asynchronous）的环境中（即两个正常运作的节点间，网路延迟没有上限），只要有一个恶意的节点存在，就没有演算法能在有限的时间内达成共识。但值得注意的是，[ "Las Vegas" algorithms ](https://en.wikipedia.org/wiki/Las_Vegas_algorithm)在每一轮皆有一定机率达成共识，随着时间增加，机率会越趋近于1 。而这也是许多成功的共识演算法会采用的解决办法。

* 容错的上限- 由[ DLS 论文](http://groups.csail.mit.edu/tds/papers/Lynch/jacm88.pdf) 我们可以得到以下结论： (1）在部分非同步（partially synchronous）的网路环境中（即网路延迟有一定的上限，但我们无法事先知道上限是多少），协议可以容忍最多1/3 的拜占庭故障（Byzantine fault）。(2）在非同步（asynchronous）的网路环境中，具deterministic 性质的协议无法容忍任何错误，但这篇论文并没有提及[ randomized algorithms](http://link.springer.com/chapter/ 10.1007%2F978-3-540-77444-0_7) 在这种情况可以容忍最多1/3的拜占庭故障。(3）在同步（synchronous）的网路环境中（即网路延迟有上限且上限是已知的），协议可以容忍100% 的拜占庭故障，但当超过1/2 的节点为恶意节点时，会有一些限制条件。要注意的是，我们考虑的是"具认证特性的拜占庭模型（authenticated Byzantine）"，而不是"一般的拜占庭模型"；具认证特性指的是将如今已经过大量研究且成本低廉的**公私钥加密机制**应用在我们的演算法中。

工作量证明机制[ 已被Andrew Miller及其他人分析过 ](https://socrates1024.s3.amazonaws.com/consensus.pdf)，是一个仰赖同步的网路环境的模型。我们可以将网路设定为有接近无穷数量的节点，而每一个节点拥有非常小的算力，且在一定时间内有非常小的机率可以产生区块。在这个设定中，假如没有网路延迟存在，则此协议有50%的容错率。经过观察，以太坊有约46%而比特币拥有约49.5%的容错率，但如果网路延迟和产生区块时间相当时，容错率会降低至33% ，若网路延迟趋近无限，则容错率趋近零。

权益证明机制则是包含在拜占庭容错共识模型中，因为所有验证者皆是已知且系统会记录验证者的数量。权益证明机制的研究一般可分为两个路线，一个是同步的网路环境模型，一个是部分同步的网路环境模型。链型态的权益证明机制演算法几乎都仰赖同步的网路环境模型，而它们的安全性分析也都可用这些模型以相似于[ 工作量证明机制 ](http://nakamotoinstitute.org/static/ docs/anonymous-byzantine-consensus.pdf)的方式来分析证明。另一个路线将部分同步网路环境中的传统拜占庭容错演算法和权益证明机制做连结，但解释比较复杂，在后面的章节会有更深入的探讨。

工作量证明机制演算法和链型态的权益证明机制演算法都偏好资料的**可用性**而非资料的**一致性**，但拜占庭容错类的共识演算法更倾向于选择资料的**一致性**，[ Tendermint ](https://github.com/tendermint/tendermint)明确地选择资料一致性的特质。而Casper则采用混合的模型，此模型偏好资料的可用性，但尽可能的确保资料的一致性，它让链上的应用和使用者在任何时间都能知道当前资料的一致性有多大的保证。

Ittay Eyal和Emin Gun Sirer的[ selfish mining研究 ](https://bitcoinmagazine.com/articles/selfish-mining-a-25-attack-against-the-bitcoin-network-1383578440)结论-在不同网路环境的模型中，比特币挖矿的激励兼容性（incentive compatibility）分别受到25%及33%的限制，即只有在25%或33%的矿工同谋不可能发生的前提下，挖矿的机制才是激励兼容的（即矿工按照正常的方式挖矿：有多少算力获得多少报酬）。这个结论和传统的共识演算法的结论无关，因为传统共识演算法的结论并没有牵涉到激励兼容性。

### 什么是"无成本风险"问题及该如何解决这个问题？

在许多之前（链型态）的权益证明机制演算法，包含Peercoin，只有对产生区块给予相对应的奖赏但并没有惩罚。这在出现多条相竞争的链（即分叉）的情况时，会有非预期的影响，因为每个验证者皆有动机在每一条相互竞争中的链上产生区块（以下将下注和产生区块视为相同意思）来确保他们会获得奖赏，如下：

![](https://raw.githubusercontent.com/vbuterin/diagrams/master/possec.png)

在工作量证明机制中，这么做会导致矿工的算力被分散，导致获利下降：

![](https://github.com/vbuterin/diagrams/blob/master/工作量证明机制sec.png?raw=true)

当给予区块奖赏的同时却没有惩罚，结果就会造成-如果每个验证者都是狭义上（narrowly）经济理性的话，则即便在没有任何攻击者的情况下，区块链本身也没办法达成共识。因为每个验证者都在每条链上下注。如果有攻击者，攻击者只需要赢过那些执行利他行为（altruistic，即只会在单一条链下注）的节点即可，不需要赢过那些经济理性的节点。相反的在工作量证明机制中，攻击者必须要同时赢过利他节点和经济理性节点（但这确实是可行的攻击：参考SchellingCoin的[ P + epsilon攻击 ](https://blog.ethereum.org /2015/01/28/p-epsilon-attack/)）。

有些人会认为下注者有动机按照规则来下注且只下注在最长的链上，好让他们的投资能够保值。然而这个论点忽略了这个动机受制于公地悲剧理论（[ tragedy of the commons ](https://en.wikipedia.org/wiki/Tragedy_of_the_commons)）：每个下注者可能只会有1%的机会成为关键（pivotal）的角色（即他的决定会影响一个攻击的成败），所以用来买通他们的贿络金额只需要是他们总赌注金额的1% 。因此，全部的贿赂金额只需要是下注总额的0.5-1% 。此外，本段开头的论点同时暗示着任何"不可能失败"的情况都不是一个稳定的平衡，因为不可能失败的情况代表每个下注者成为关键角色的机会是零，即只要贿赂金额超过0%都能让下注者有动机参与攻击。

有两种方式可以解决这个问题。第一个为"Slasher"，在[ 这篇文章 ](https://blog.ethereum.org/2014/01/15/slasher-a-punitive-proof-of-stake-algorithm/)有大略地描述，并进一步由[ Iddo Bentov ](https://arxiv.org/pdf/1406.5694.pdf)开发。当验证者同时在不同条分叉的链上下注（产生区块）的情况发生时，将证据纪录进区块链中并以此销毁验证者的下注资本。这让动机结构改变如下：

![](https://github.com/vbuterin/diagrams/blob/master/slasher1sec.png?raw=true)

注意，这个演算法要能执行，**验证者是哪些人**需要事先就知道。否则验证者可以任意选择要下注的链：即当A链可下注就下注A链，当B链可下注就下注B链，当两条都可以下注就下注最长的链。所以事先确定验证者的名单可以避免这种情况发生。但这也有缺点存在，包括要求节点需要频繁地上线来获得安全可信的链的状态（即确认区块是不是由合格的验证者所产生），并且让medium-range的验证者共谋攻击有可能发生（例如连续三十个验证者中有25个预谋发起攻击来回复过去19个区块），因为验证者事先知道什么时候会轮到他产生区块。如果这些风险是可接受的那就没太大问题。

第二个方式单纯地惩罚在错的链产生区块的验证者。也就是当有两个互相竞争的A和B链，如果有一个验证者在B上面产生区块，则他可在B链上获得R 的奖赏，但这个区块的标头（header）资料会被记录在A链上（在Casper 中叫做"dunkle" ）且他在A链上会受到F 的罚金（ F 可能等于R ）。这会将结构改变成：

![](https://github.com/vbuterin/diagrams/blob/master/slasher2sec.png?raw=true)

直觉来说，我们可以把工作量证明机制的经济模型复制到这来用。在工作量证明机制中，在错的链上产生区块同样有惩罚，但这个惩罚并不显而易见：矿工额外的电力或硬体成本花费（因为要同时在两条链上花费运算）。第二个方式的一个缺点是，它将些微的风险加注到验证者身上（因为验证者要承担在错的链上产生区块的成本），不过这个风险会随者时间慢慢减退，但另一方面，它的优点是不需要事先知道验证者有谁。

### 上一章节介绍链型态的权益证明机制如何解决"零风险成本"问题，那拜占庭容错相似的权益证明机制又是怎么运作的呢？

拜占庭容错类型（部分同步的网路环境）的权益证明机制演算法允许验证者藉由送出遵守两类别规则的签名讯息，来对区块进行"投票"，这两类规则分别是：

*  **终局条件（Finality conditions）** -规则用来决定某杂凑值是否可被视为不可更改的（finalized）。
*  **删砍条件（Slashing condition）** -规则用来决定是否有足够理由怀疑某个验证者作弊（例如同时下注多个相冲突的区块）。

如果有验证者触发其中任何一条规则，他们的资本将全数被删去。

以下举两个例子来说明不同删砍条件的发生场景，下面的" 2/3的验证者"代表"全数验证者资本总和的2/3，而不是验证者数量的2/3 "，其他的比例亦相同。在这些例子中，"PREPARE"和"COMMIT"可单纯地理解为两种验证者可送的签名讯息（`MESSAGE`）。

1.如果`MESSAGE`包含：`["COMMIT", HASH1, view]`和`["COMMIT", HASH2, view]`，其中`view`为相同但`HASH1`和`HASH2`不同，且皆由同一个验证者所签名，则该验证者的资本被删去。即不能同时对相冲突的区块做签名。
2.如果`MESSAGE`包含：`["COMMIT", HASH, view1]`，则**除非**  `view1 == -1`，或同时存在其他包含`["PREPARE", HASH, view1, view2 ]`的签名讯息（其中`view2 < view1`）且这些讯息由至少2/3的验证者所签名，则对`"COMMIT"`签名的验证者的资本被删去。即一个`HASH`值只有经过至少2/3 `PREPARE`才能被`COMMIT`。

合适的删砍条件需要有两个重要的要求：

*  **可咎责的安全性（Accountable safety）** -如果相互冲突的`HASH1`和`HASH2`（即分叉）都被认定为不可更改，则至少有1/3的验证者肯定违反了某些删砍条件。
*  **Plausible liveness** -除非至少1/3的验证者违反了某些删砍条件，否则必定存在某些合法的讯息是2/3的验证者可以签的，且这些讯息会让某些杂凑值变成不可更改（finalized）。即除非至少1/3的验证者违规，否则一定可以让新的杂凑值被finalize。

如果我们有一组删砍条件可以达成这两个要求，我们便可以提供验证者足够的动机，并开始从economic finality 的特性中得到成果。

### 一般来说，什么是"经济面上终局的特性"？

经济面上终局指的是：当区块被认定为不可更改，或更一般来说，有一种讯息获得足够数量的签名，则唯一让链在未来纳入另一个相冲突的区块的方法是有一大群的人愿意赔上一大笔钱。如果一个节点看到某个区块符合经济面上终局的特性，则他有经济面上非常大的保证这个区块会成为链的一部分历史（且这条链也是大家都认可的）。

达成经济面上终局有两种方法：

1.如果有足够多的验证者对以下形式的声明进行签名，则一个区块可被视为具有经济面上的终局："当区块B没有被收入则我会失去X的资本"。这让使用者获得了如下的保证- (I)区块B是链的一部分，或是(II)若验证者想骗他们，让他们相信区块B是有被收入的，则验证者会损失一大笔钱。

2. 如果有足夠多的驗證者簽名表達支持收入區塊B，而且有方式能在驗證者違規時提出數學證明（_當不同於區塊B的某區塊B'也以同樣方式被收入_）並讓這些驗證者損失一大筆錢，則一個區塊可被視為經濟面上的不可更改。如果使用者看到這個被收入的區塊，並驗證了鏈的有效性，且藉由有效性（validity）和不可更改性（finality）他們可以在發生分叉的鏈之中做出選擇，則他們能獲得如下的保證 - (I)區塊B是鏈的一部分，或是 (II)若驗證者同時也參與了另一條互相競爭且亦符合終局條件的鏈，則驗證者會損失一大筆錢。

兩種達成終局（finality）的方法分別繼承自"零風險成本問題"的兩個解決方法： 藉由懲罰錯誤（如`"COMMIT"`不合法的區塊）來達成終局 及 藉由懲罰不明確性（如`"COMMIT"`兩個衝突區塊）來達成終局。第一個方法的主要優點是輕客戶端（light client）使用者也能驗證且比較直覺易懂；第二個方法的主要優點有 (I)比較容易瞭解為何誠實的驗證者不會被懲罰及 (II)干擾因素（griefing factors）對誠實的驗證者比較有利 - 相比於不誠實者干擾誠實者所要付出的成本，誠實者干擾不誠實者的成本是比較低的。

Casper 遵循第二種方法。不過可以透過增加鏈上的機制，讓驗證者可以自行選擇是否要對第一種方法的聲明（"當區塊B沒有被收入則我會失去X的資本"）簽名，此舉可讓更多輕客戶端使用者增加效率。

### 所以這和拜占庭容錯理論有什麼關聯？

傳統的拜占庭容錯理論在 safety 和 liveness 上和我們有相似的要求。首先，傳統拜占庭容錯理論要求當超過 2/3 的驗證者是誠實的時候，safety必須要被達成。嚴格來說這是比較容易實現的模型，傳統的拜占庭容錯理論嘗試證明"如果共識機制無法達成safety，則我們知道至少有 1/3 的驗證者是惡意的"；而我們的模型則是嘗試證明"如果共識機制無法達成safety，則我們知道至少有 1/3的驗證者是惡意的，而且我們知道是哪些驗證者，即便你在出現問題的當下不在線上"。從liveness的角度，我們的模型比較容易達成，因為我們不需要證明**共識會被達成**，我們只需要證明機制**沒有卡住**。

不過幸運的是，額外的"可咎責的"（accountable）特性需求其實不難實現；事實上，只要協議有正確的防禦機制（protocol armor），我們都可以將任何不管是部分同步或是非同步的傳統拜占庭容錯演算法轉換成可咎責的演算法。這個證明基本上歸結於一個事實--拜占庭故障（fault）可以被窮舉並分類，而這每一類要不是 (I)可咎責的（如果你`"COMMIT"`了這類的訊息，則你會被逮到，且我們可以為此建立一條刪砍條件的規則），要不就是 (II)無法被分辨是網路延遲還是故障（注意，即便是太早送出訊息這種故障，也沒辦法被分辨出來）。

### 什麼是弱主觀性（weak subjectivity）？

首先很重要的一點是，利用存款（deposit，也就是驗證者加入的資本）來確保"風險成本不為零"的機制，改變了權益證明機制的安全模型假設（security model）。假設 (I)存款會被鎖住一個月，時間到之後可以提走， (II)有個 51% 攻擊嘗試反轉（revert）長達 10 天的交易量，則這些攻擊者產生的區塊會被寫入鏈裡當作證據且驗證者會被懲罰。然而，假設攻擊變成長達 40 天，則雖然這些攻擊產生的區塊可以再被寫入鏈裡，但驗證者早已能把錢提走而不會受到懲罰。為了要解決這個問題，我們需要一個"反轉限制（revert limit）"的規則，也就是當反轉所影響的區塊總時間長度超過存款鎖住的期限，則節點可以拒絕接受這些區塊（在上例，即拒絕影響超過一個月的反轉區塊）。這表示節點現在多了兩項要求：

1. 當節點第一次連上並要同步鏈的資料的時候，他們必須藉由鏈外的方式來驗證最新的狀態，即透過朋友節點們或各個 Block Explorer 等等的方式。如果他們得到的都是同一條一樣的鏈，則可以確定這條是正確的。注意，只有在出現鏈分叉長度超過反轉限制時（在上例，即得到兩條在過去超過一個月的區塊皆不相同的鏈）才需要這種採用這種鏈外的交際驗證（social authentication）。

2. 節點每隔一段的時間（"反轉限制"時間）就必須要上線同步。如果沒定時同步，則需要再透過一次鏈外的交際驗證來保證狀態的可信度。

如果攻擊者要利用鏈外交際這個管道來攻擊，他們必須要說服社群裡一大部分的人，讓他們相信攻擊者的鏈才是有效的；或是改為說服新加入社群的人：新加入的人可能會在下載軟體時一並收到最近一次的檢查點（checkpoint，即反轉限制的臨界點），但如果攻擊者能竄改這個檢查點的紀錄，則他們要能直接竄改整個軟體也不再是件難事，而且沒有單純的密碼經濟學的驗證方式能解決這個問題。當一個節點連接上了，只要他夠頻繁地上線，他就能以密碼經濟學上安全的模型來確保連接上正確的鏈，而不需要額外的鏈外交際驗證。

另外，這種交際驗證如果需要，也可以直接加入進使用者使用的過程中：如 (1)[BIP 70](https://github.com/bitcoin/bips/blob/master/bip-0070.mediawiki)的交易就要求交易裡要加入最近一段時間的某個區塊的雜湊值，使用者的軟體會在交易成立前，藉此確保使用者和商家是在同一條鏈上（也可以透過其他鏈上的互動方式）。 或(2)，採用Jeff Coleman的 [universal hash time](https://www.youtube.com/watch?v=phXohYF0xGo)。採用UHT的話，如果攻擊要能成功，攻擊者必須在被攻擊鏈繼續增長的**同時**，暗中產生另一條鏈（即攻擊者沒辦法事先或在事後短時間內產生一條相抗衡的鏈），代表這需要大多數的驗證者共謀了一段非常長的時間。

### 在權益證明機制裡可以用經濟上的方式來懲罰審查（censorship）行為嗎？

審查行為比起交易反轉要更難去證明。區塊鏈本身無法分辨 (1)"使用者 A 嘗試送出交易 X 但被審查過濾掉了" 或是 (2)"使用者 A 送出交易 X 但因為交易費不夠而沒被收入區塊裡" 或是 (3)"使用者 A 從未送出交易 X "。但仍有一些方法可以對抗審查行為。

第一個是使用停機問題（halting problem）。這個方法比較弱的版本是將協議設計成圖靈完備，使得驗證者無法知道一筆交易會不會在花費他大量的運算後因為出現預期外的行為而出錯，但這同時也讓驗證者面臨潛在的 DoS 攻擊。這也是當初[ the DAO 軟分叉](http://hackingdistributed.com/2016/07/05/eth-is-more-resilient-to-censorship/)沒有實行的原因。

比較強的版本則是讓交易在未來中短期的時間內觸發特定的效果。使用者可以送出多筆相互關聯的交易及利用可預期的第三方的資訊來導致未來事件的發生，想要進行審查的驗證者要等到交易都被收入區塊（並確認為不可更改）才能知道發生了什麼事件，但此時要阻止交易又已經太遲。即便過濾掉所有相關的交易，審查者想阻止的事件還是會發生。審查者可以試著過濾掉每一筆交易，或是過濾掉沒有附上相關證明（證明交易不會導致任何非預期的情況發生）的交易，但這麼做會擋掉非常多不同類型的交易以至於讓整個系統失靈，審查者的存款價值也會跟著該數位貨幣的價值崩盤而下降。

第二個方法是（[如 Adam Back 在這篇文章](https://www.reddit.com/r/Bitcoin/comments/4j7pfj/adam_backs_clever_mechanism_to_prevent_miners/d34t9xa)）所介紹，要求交易都經過[timelock-encrypted](https://www.gwern.net/Self-decrypting%20files)加密。所以審查者只能在不知道交易的內容的情況下將交易收入區塊，直到之後某個時間點交易內容被揭露，但此時要過濾掉交易已經太遲。但是審查者可以選擇只收入有附上解密證明（如利用 zkSNARK 等零知識證明）的交易；這雖然會強迫使用者必須要去下載相關的使用軟體，但審查者可以直接提供所需軟體。這在賽局理論中，使用者是有動機去配合的。

或許在權益證明機制中比較好的做法是使用者透過軟體更新來執行硬分叉，將惡意的驗證者移除。這個方法和下載解密軟體來配合審查的方法相比，並沒有多難。總之，第二個方法雖然會降低和鏈溝通互動的速度（注意，採用這個方法必須是強制的才會有效，否則審查者只需要過濾掉經過加密的交易並收入沒加密的交易即可），卻也是比較適度且有效的。

第三個方法是在鏈分叉發生時，將偵測審查行為發生的機制加進分叉選擇的考量。原理很簡單，節點持續觀察著網路及交易，如果他們發現某筆交易帶有夠多的手續費卻遲遲未被收入，就給沒有收入這筆交易的鏈較低的評分。如果所有的節點都遵守這規則，則最終較弱勢的鏈也會因為收入了這個交易而讓其他誠實的節點都轉而加入這條鏈。這個方法主要的缺點是，離線的節點還是紀錄者強勢的（有審查機制的）鏈，如果在他們重新上線之前審查行為就結束了，則會造成上線的（誠實的）節點間的分歧。因此這個方法比較適合被用來當作緊急情況如硬分叉發生時的一個節點間的協調工具，如果是用在幾乎每天都會發生的鏈分叉選擇考量則不太合適。

### 驗證者是怎麼選出的？什麼又是stake grinding？

在任何鏈型態的權益證明機制演算法中，都需要一個機制來隨機選出哪個驗證者可以產生下個區塊。例如，假設目前活躍中的驗證者包含 資本為 40 元的的 Alice、資本為 30 元的 Bob、資本為 20 元的 Charlie 及資本為 10 元的 David，則你希望他們各自被選出的機率分別為 40%、30%、20%及10%（當然在實際情況中，你會希望選出來的是一連串無限的候選人而不是一個，這樣當前面一位沒出現，後面一位就可以遞補，但這不影響根本的問題）。在非鏈形態的演算法中，一樣會因為不同原因而需要隨機性（randomness）。

"Stake grinding"是一種驗證者試圖透過一些計算或其他方式來影響隨機性的攻擊。例如：

1. 在 [Peercoin](https://bitcointalk.org/index.php?topic=131901.0) 中，驗證者可以搜尋各種參數的組合並找到特定的參數來增加他們產生有效區塊的次數。

2. 在一個目前已經不使用的方式裡，第 N+1 個區塊的隨機性取決於第 N 個區塊裡的簽章。這讓驗證者可以重複產生新的簽章直到他們找到一個特別的簽章來讓他們能預測並掌握下一個區塊，以藉此控制系統。

3. 在 NXT 中，第 N+1 個區塊的隨機性取決於產生第 N 個區塊的驗證者。這讓驗證者可以藉由跳過一個產生區塊的機會來操縱隨機性。雖然這麼做的機會成本是損失一個區塊獎賞，但有時候新產生的隨機種子可以讓驗證者在未來數十個區塊中獲得高於平均區塊獎賞的獎勵。[這裏](http://vitalik.ca/files/randomness.html)有更詳細的分析。

\#1和\#2很容易解決；一般的做法是要求驗證者事先存款來避免驗證者一直改變身份（address）來找到可以影響隨機性的值，並避免使用可以輕易被操縱的訊息，例如一個區塊裡的簽章。有幾個主要的策略來解決\#3。第一個是利用 [secret sharing](https://en.wikipedia.org/wiki/Secret_sharing) 或是 [deterministic threshold signatures](https://eprint.iacr.org/2002/081.pdf) 並要求驗證者一同產生隨機值。這些方法在大多數驗證者沒有同謀的時候都足夠穩固（看各種應用不同，33%-50% 的驗證者合謀就可以干預，使得協議對維持 liveness 的機率假設剩下 67% ）。

第二個方法是使用密碼學的方式：驗證者事先 commit 一些訊息（如公布 `sha3(x)`），接著在區塊內公佈 `x` 值，最後將 `x` 值和其他人的隨機值加在一起。理論上針對這個方法有兩種潛在的攻擊。

1. 在commit時操縱 `x` 值。但因為結果會將許多人的 `x` 值一起加入考量，其中只需要一個人是誠實的，隨機性的分佈就會呈常態分佈，所以這攻擊不太可行。

2. 選擇性地不公開區塊。這種攻擊的機會成本是損失一個區塊獎賞，而且這個方法頂多只能讓一個人看到下一個區塊的驗證者是誰，所以最多可能的獲益也是一個區塊獎賞。唯一的例外是，如果一個驗證者跳過，則遞補上來的驗證者和下一個區塊的驗證者有可能會是同樣一個驗證者。可以用懲罰的方式來抵消驗證者跳過的動機。

第三個方法是使用 [Iddo Bentov 的 "majority beacon"](https://arxiv.org/pdf/1406.5694.pdf)，藉由之前產生的（也用 beacon 方式產生的） N 個隨機數字中的每個 bit 值的多數決來產生新的隨機數字（即，如果大多數數字的第一個 bit 為 1 ，則新的數字的第一個 bit 為 1 ，否則為 0 ）。攻擊的成本會是 `~C * sqrt(N)` ，其中 C 是攻擊其他 beacon 產生的隨機數字的成本。總之，有許多 stake grinding 的解決方法存在，這個問題比較像是 [differential cryptanalysis](https://en.wikipedia.org/wiki/Differential_cryptanalysis) 而不是 [halting problem](https://en.wikipedia.org/wiki/Halting_problem) - 權益證明機制的設計者最終會明瞭且會知道如何克服，不是很根本且無法彌補的缺陷。

### 針對 Casper 的 51% 算力攻擊會是怎麼樣的攻擊？

51% 攻擊最基本的形式就是 **finality reversion**：驗證者確立區塊 A 的紀錄為不可更改後又將另一個區塊 A' 也列為不可更改，打破區塊不可更改特性的保證。在這個情況中並存著兩個彼此不相容的歷史紀錄，導致鏈產生分叉。這需要仰賴社群以鏈外的方式進行協調來決定應該選擇哪條鏈，而哪條該被捨棄。

協調的管道有很多種，如社群媒體、block explorer 及交易所間的溝通、線上論壇等等。決定該選哪條鏈的原則是 "哪條先出現就選哪條" 。另一個方式是讓市場機制去決定：在很短的時間裡，兩條分叉都可以在交易所中交易，直到其中一條因為價值更高而勝出。在這種情況中，"哪條先出現就選哪條" 的原則會是市場機制的 [Schelling point](https://zh.wikipedia.org/wiki/谢林点)，即參與者會因為覺得其他人也會選擇先出現的那條鏈而傾向選擇先出現的那條，所有人在沒有溝通的情況下按照這個傾向選擇了先出現的那條鏈。所以實際中，這兩種方式並用是非常有可能的。

當該選擇哪條鏈的共識達成時，使用者（即驗證者、light node 及 full node）就可以手動地將勝出區塊的雜湊值藉由特殊的選項寫入軟體中，之後他們的節點就會忽略其他不包含該雜湊值的鏈。之後不管是哪條鏈被選擇，都有證據可以用來懲罰至少 1/3 的違規驗證者。

另外一種攻擊是阻斷 liveness：一個由超過 34% 驗證者組成的集團可以拒絕和其餘的驗證者合作。在這種情況下，將沒有區塊能被變成不可更動。Casper 採用混合（鏈 + 拜占庭容錯）型態的共識，因此鏈還是會持續增長，但安全性會大大降低（因為一直沒有新的區塊可以被視為不可更改）。如果很長一段時間（例如一天）都沒有區塊變成不可更改，則有以下幾種選項：

1. 可以採用一個自動化的功能來輪轉驗證者名單，瓦解集團的佔比。在新的驗證者名單中區塊有機會被變為不可更改，但使用者會收到提醒告訴他們這些不可更改的區塊還是不能全信的，因為很有可能舊的一組驗證者會重新奪回控制權並改為將其他的區塊變為不可更改。使用者如果確信舊的一組驗證者不會再上線，就可以忽略這些警告。在這種情況發生時，所有舊的驗證者如果沒有再繼續參與共識過程，則他們會受到相當大筆的罰款。

2. 採用硬分叉的方式移除集團驗證者的存款，並增加新的驗證者。

在第二種方法中，分叉還是一樣要由鏈外的共識來協調，且可能會由市場機制的方式（即兩條擁有不一樣驗證者組成的鏈短暫的並存於交易市場上）。如果是藉由市場共識的方式，有個有力的論點是：市場會傾向選擇 "好人勝出" 的鏈，這條鏈的驗證者展現了他們的誠意（或至少他們和使用者的利益是並存的），因此也是一條對應用開發者較有用的鏈。

選擇攻擊應對的策略如社交協調或機制內自動化，兩者之間其實有如一道光譜，並不是非黑即白。通常設計越往自動化的解法越理想，因為這可以降低當 51% 攻擊和社交層面（包含市場共識如交易所）的攻擊同時發生時的風險。可以想像一個採用 \#1 的措施：節點在超過一定時間都沒有區塊變為不可更改時自動更換驗證者名單，這會降低交際協調的需要，但節點也因此要更頻繁地保持上線。但不管是哪種方式，攻擊者都會損失一大筆的錢。

另外一種比較不容易發覺的攻擊是審查攻擊：超過 34% 的驗證者拒絕將含有某些特定交易的區塊變為不可更改，除此之外鏈的運作都正常。攻擊的範圍從輕微的，干擾特定應用的攻擊（如過濾 Raiden 或閃電網路的交易是較簡單偷錢的方式）到阻擋所有交易的大範圍攻擊。

其中又分成兩種情況，第一個是攻擊者佔 34%-67%。在這種情況中，正常的驗證者可以拒絕將他們主觀認定為正在過濾交易的區塊（即攻擊者產生的區塊）變成不可更改或接在後面，這讓這種攻擊變為一個標準的針對 liveness 的攻擊。比較危險的情況是當攻擊者佔超過 67%，攻擊者可以任意的阻擋他們不喜歡的交易並拒絕接在包含這些交易的區塊後面。

面對這個攻擊有兩道防線。第一，以太坊具有圖靈完備特性，[在本質上就具有抵抗審查的能力](http://hackingdistributed.com/2016/07/05/eth-is-more-resilient-to-censorship/)，因為審查交易的過程在某種程度上相似於解決停機問題（halting problem）。但因為區塊有 gas 限制，所以審查並不是不可能，不過用"簡單"的方式來審查反而會讓攻擊者自己有被 DoS 的風險。

單純具有這個抵抗能力[還不夠好](https://pdaian.com/blog/on-soft-fork-security/)，還有其他方式可以加強抵抗審查的能力。最有趣的方式是增加一個機制內的功能：讓交易能自動規劃未來的事件，因為預測一個事件的執行結果或是連鎖事件是很難的。驗證者可以藉由混淆事件規劃的順序來加入成為驗證者，藉此稀釋攻擊者的佔比到低於 33% 。

第二，引進 "active fork choice rule" 的概念：當面臨鏈分叉，其中一個選擇鏈的考量是和鏈進行互動並藉此驗證該鏈是否有在過濾你的交易。最有效的方式是節點重複地送出一筆交易來規劃下注並在最後一刻取消。如果節點偵測到審查機制，就不取消交易並暫時加入成為驗證者之一，將攻擊者的佔比稀釋到 33% 。如果集團過濾掉他們的交易，則採用這個 "active fork choice rule" 的節點就不會選擇這條鏈。這會讓審查攻擊轉變為 liveness 攻擊，此時就可以藉由解決 liveness 攻擊的方式來處理。

### 聽起來似乎很仰賴鏈外的社交協調，這樣難道不危險嗎？

攻擊 Casper 代價非常高。以下我們將會講到，攻擊 Casper 的代價至少和買礦機持續不斷的對採用工作量證明機制的鏈發動 51% 攻擊直到無效果為止的代價一樣。因此，上面段落所描述的復原方法只有在非常極端的情形才會用到。事實上，工作量證明機制的提倡者亦表達在某些相似情況採用社交協調的意願，例如[改變工作量證明機制的算法](https://news.bitcoin.com/bitcoin-developers-changing-proof-work-algorithm/)。所以權益證明機制需要的社交協調是否會比工作量證明機制所需要的社交協調還多還無明確的結果。

在現實中，我們預期用到社交協調的方式的次數會接近零次，因為攻擊者會瞭解到單純為了讓區塊鏈停擺一兩天要花費這麼大筆的錢是不符利益的。

### 邊際成本趨近邊際收益不就表示所有具有一定高度安全層級的共識演算法都一樣有效（或一樣地浪費）？

許多人都提出過這個論點，而解釋最清楚的就屬[Paul Sztorc 的這篇文章](http://www.truthcoin.info/blog/工作量證明機制-cheapest/)。其中的重點大概是：如果你創造一個有 100 元獎賞的機會，則大家為了得到它會願意花費最高到 99.9 元（包含自己付出的勞力），此時邊際成本趨近邊際效益。因此，這個理論說：任何提供區塊獎賞的演算法（不管是權益證明機制或工作量證明機制），其中為了獲取獎賞而進行對社會無效益的活動的數量都是一樣的，即它們都一樣地浪費資源。

這個理論有三個盲點：

1. **單純地說邊際成本趨近邊際效益是不夠的，必須還要假設一個真的有人可以花費那些成本的機制存在。** 例如，假設我明天宣布未來每一天我都會隨機從一個十人名單中挑出一個人並給予他 100 元，然而沒有人有辦法花費 99 元來取得其中的隨機值。他們要不是不在名單中拿不到獎賞，要不就是在名單中但沒有任何有效的方法取得我的隨機值，只能獲得期望值為平均每天 10 元的獎賞。

2. **邊際成本趨近邊際效益不表示總成本趨近總收益。** 例如，假設存在一個演算法利用偽隨機（pseudo-randomly）的方式從一大群驗證者中選擇 1000 位驗證者(一個驗證者獲得 1 元獎賞)。如果你資本佔總資本的 10% 則你平均會獲得 100 元。假設你可以花費 1 元來（無限次地）重設隨機值，因為 [central limit theorem](https://en.wikipedia.org/wiki/Central_limit_theorem)，你可獲得的獎賞的標準差是 10 元，又因為[其他已知的數學結論](http://math.stackexchange.com/questions/89030/expectation-of-the-maximum-of-gaussian-random-variables)， N 個隨機抽樣中最大的期望值約略小於 ` M + S * sqrt(2 * log(N))` ，其中 M 是中間值且 S 是標準差。因此增加重設隨機值的次數（即增加 N ）所獲得的獎賞會快速地下降，例如如果完全不嘗試重設隨機值你的期望獲利是 100 元，嘗試一次是 105.5 元，兩次是 108.5 元，三次是 110.3 元，四次是 111.6 元，五次是 112.6 元，六次是 113.5元（只增加 0.9 元的獲利）。因此嘗試超過五次之後就不值得再繼續嘗試。所以一個由經濟因素所驅動的攻擊者，如果他總資本佔 10% ，則他會花費 5 元嘗試重設隨機值來獲得額外的 13 元的獲利，雖然這麼做很沒效率。如果一個機制可被有心人士利用，但被利用的機率不高，則損失不會多。但這不適用於在工作量證明機制中因為出現一個漏洞而導致全部資源投入而造成浪費的情況。而這點也和下一章節要介紹的 capital lockup costs 非常相關。

3. **權益證明機制要變得安全穩固所需要的獎賞比起工作量證明機制的獎賞少的非常多。**

### 什麼又是 capital lockup costs?

將 X 數量的 ether 鎖進存庫是有代價的，例如犧牲選擇其他選項的機會。如果我有 1000 ether，我想怎麼使用就怎麼使用，但如果我將它鎖在存庫裡數個月，而且沒有保險來支付可能的意外支出的時候該怎麼辦？在這段時間我同時也失去將 ether 轉換成其他代幣的自由。我可以透過賣空相等數量 ether 的方式來模擬賣掉我的 ether，但會有交易手費續和利息的成本。有些人可能會認為： captital lockup 造成的經濟上的不便和工作量證明機制造成的經濟層面上無效率的程度是一樣的。但答案是否定的，如同上一章節的理由\#2和理由\#3。

我們先從理由\#3開始講起。考慮一種模型：權益證明機制存款是無限期的、ASICs可以永久持續運作、ASIC技術固定（即不適用摩爾定律）而且電力花費是零，並假設穩定的利率是每年 5%。在工作量證明機制裡，我花 1000 元買了礦機，礦機每年給我 50 元的利潤直到永遠。在權益證明機制中，我存 1000 元（因為存款是無限期的所以這筆錢當作花掉）並獲得每年 50 元的利潤直到永遠。到目前為止，兩種情況看起來是等價的（雖然技術上來說，在權益證明機制中當我的存款因違規被銷毀時，會間接造成其他人的存款價值升高，但這邊我們先不討論）。在這個假設下，不管是權益證明機制或工作量證明機制，任何人要發動 "Maginot-line" 51% 攻擊（即硬體買得比網路其他人加起來還多）的成本都會因為我的加入而再多上 1000 元。

現在假設模型依序做以下的變更：

1. 摩爾定律適用，ASICs 每 2.772 年貶值 50%（為方便計算，假設其價值每年持續降低 25%）。如果我要繼續保持 "付一次，永遠都能持續拿回錢" 的模式，我可以將 1000 變成一筆資金，其中167用來買 ASICs ，833 元花在 5% 報酬率的投資。833元的投資產生每年 41.67 元的利潤剛好足夠花在更新 ASICs 設備上（為方便計算，假設技術發展是穩定連續的）。這時挖礦的利潤會降低至 167 * 0.05 = 每年 8.33 元，因此 83.3% 的礦工會退出競爭，直到回到每年 50 元利潤的穩定狀態，所以這時發動 Maginot-line 51% 攻擊的成本會縮小至少六倍。

2. 電力加上硬體維護組成大約 1/3 的挖礦成本。1/3 是從最近的數據估計而來的：Bitfury 的新資料中心 [每 gigahash 電力消耗為 0.06 焦耳 ](http://www.coindesk.com/bitfury-details-100-million-georgia-data-center/)，或 每 terahash 60 焦耳、每terahash 0.000017千瓦小時。如果假設比特幣網路的平均消耗皆如此的話，以[比特幣總共算力約 1.67 million TH/s](http://bitcoinwatch.com/) 來算，每秒約消耗 27.9 千瓦小時。中國電力成本為[每千瓦小時 0.11 元 ](http://www.statista.com/statistics/477995/global-prices-of-electricity-by-select-country/)，約為每秒 3 元或每天 26 萬元。比特幣區塊獎賞加上手續費為 600 * 13 * 144 = 一天 112 萬元。因此電力組成約 23% 的成本，另外我們可以用簡單的計算預估硬體維護成本為 10% 。這表示你的 1000 元資金裡，只有 111 元要拿來買 ASICs，55 元要拿來付持續性的花費如電力和維護等，而 833 元會花在投資上，因此現在要發動 Maginot-line 51% 攻擊的成本已經是一開始的至少九倍小了。

3. 事實上存款是短暫而非永遠（被視為拿不回來）的，當然你自願永遠存著的話也行。這讓我多了一些空間選項，我可以在任何時間內結束並等待一段時間（如四個月）。這表示我願意花更多的錢來獲得更多的利潤（因為投資不會再被當作拿不回來的錢），或許是 3000 元。因此，在權益證明機制裡發動 Maginot line 51% 攻擊的成本增加為原本的三倍，和工作量證明機制比起來是 27 倍的安全性。

以上包含了很多簡化過的計算，但它的目的是為了指出經過許多因素考量，都顯示出權益證明機制有更高的安全性。而這個[看似可疑的多重因素論點](http://lesswrong.com/lw/kpj/multiple_factor_explanations_should_not_appear/)為何這麼強烈凸顯權益證明機制的優點的主要理由是：在工作量證明機制中，我們操作並利用物理特性；而在權益證明機制中，我們可以設計出一套準確具有理想特性的機制 - 簡而言之，我們可以用我們的方式來優化 "物理特性"。在安全模型上的改變，特別是弱主觀性（weak subjectivity）這個性質的出現，讓我們能得到以下結論 - **權益證明機制要變得安全穩固所需要的獎賞比起工作量證明機制的獎賞少的非常多。**。

接者我們可以討論 邊際成本/效益 和 總成本/效益 的不同。在 capital lockup costs 的情況中這非常重要。例如假設一個情況，你有價值 100000 的 ether。鎖住其中的 50000 應該不會有什麼問題，鎖住 80000 可能會有一點不方便雖然 20000 還是夠充足，鎖住 90000 就有點問題了，99000 問題就大了，全鎖住那你可能是瘋了，因為你會連交易費都出不起。因此你的邊際成本快速的增加，我們可以用以下方式比較權益證明機制情況和工作量證明機制情況的不同：

![](https://blog.ethereum.org/wp-content/uploads/2014/07/liquidity.png)

可以看到在權益證明機制的總成本是遠小於存入 1 ether 的邊際成本乘上現有所有的存款總量。

注意，這部分的論點可惜地並沒有完全解釋到 "貨幣的安全發行量（safe level of issuance）"。但其顯示出即使我們將貨幣發行量控制地很低，我們還是能獲得可觀的 權益證明機制參與人數，雖然這也代表很大一部分的發行量會被用來獎賞驗證者。

### 在權益證明機制的礦池會有類似工作量證明機制礦池中心化的風險嗎？

從 [Bitcoin](https://blockchain.info/pools) 和 [Ethereum](https://etherscan.io/stats/miner?range=7&blocktype=blocks) 來看，大約需要三個礦池聯合才能發動 51% 攻擊（ 在寫這篇文章的時候，Bitcoin 約需四個、Ethereum 約需三個）。假設在權益證明機制中，包含所有礦池、交易所一共有 30% 的參與率，則 [三個礦池或交易所](https://etherscan.io/accounts) 就足夠發動 51% 攻擊；如果參與率提高到 40% 則需要八個。另外礦池、交易所也不能將所有資本投入攻擊中，因為他們需要保留部分金錢來應付客戶。

再加上在权益证明机制中，组成的矿池的动机是较低的，因为这会需要较高的信任成本- 虽然矿池不偷钱，但是可以假装被骇去触发删砍条件而导致资本全被没收，同时扮成检举者领检举奖金。不过另一方面，即便需要信任对方，不需要自己跑一个full node 就能用自己的钱赚利润仍是很有吸引力的。总之，中心化和去中心化间的平衡需要经验累积，也只有等到系统真的上线一段时间了才有办法得到答案。但配上sharding 之后，我们预计会更进一步降低中心化，因为(i)需要考量的变化更少且(ii)在sharding 模型中，验证交易的负担和所投入的资本成正比，所以并不会因为组成矿池而节省成本支出。

最后一点是，中心化在权益证明机制中比其在工作量证明机制中的负面影响更小，因为从51% 攻击中复原容易且便宜多了，也不需要换新的挖矿演算法。

### 权益证明机制能被用在私有链或联盟链吗？

一般来说是可以的。任何权益证明机制演算法都可以被私有链或联盟链用做一个共识演算法。唯一不同是成为验证者的方式：一开始会由一群大家同意且信任的使用者成为验证者，接着再由这群验证者透过投票去加入新的验证者。
